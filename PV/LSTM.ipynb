{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad9cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import Hour, Minute\n",
    "from pandas.tseries.offsets import Day, MonthEnd\n",
    "from pandas.tseries.offsets import Hour\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a04266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df = pd.read_csv('Wind_deseason.csv')\n",
    "df = pd.read_csv('PV_deseason_15.csv', parse_dates=[0], index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc32dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model1(tss, scaler, df):\n",
    "    mse = []\n",
    "\n",
    "    for train_indx, val_indx in tss.split(df):\n",
    "        train = df.iloc[train_indx]\n",
    "        test = df.iloc[val_indx]\n",
    "        \n",
    "        \n",
    "        scaler.fit(train['310_PV_1'].to_frame())\n",
    "        scaled_train = scaler.transform(train['310_PV_1'].to_frame())\n",
    "        scaled_test = scaler.transform(test['310_PV_1'].to_frame())\n",
    "        \n",
    "        n_input = 3 ##check in book if this is determined with ACF PACF or something else\n",
    "        n_features = 1 ## see if we should make the neural network with multiple time series (for now just 1)\n",
    "        generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)\n",
    "     \n",
    "        mod = Sequential()\n",
    "        mod.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))\n",
    "        mod.add(Dense(1))\n",
    "        mod.compile(optimizer='adam', loss='mse')\n",
    "       \n",
    "        \n",
    "        print(mod.summary())\n",
    "        \n",
    "        mod.fit(generator,epochs=50)\n",
    "        \n",
    "         \n",
    "        last_batch = scaled_train[-3:].reshape((1, n_input, n_features))\n",
    "    \n",
    "        pred = mod.predict(last_batch)\n",
    "    \n",
    "    \n",
    "        error = 0.5*(test['310_PV_1'][0] - pred[0][0])**2\n",
    "        mse.append(error)\n",
    "\n",
    "    print(mse)\n",
    "    return mse\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce1d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelNaive(tss,df):\n",
    "\n",
    "    mse3 = []\n",
    "\n",
    "    for train_indx, val_indx in tss.split(df):\n",
    "        train = df.iloc[train_indx]\n",
    "        test = df.iloc[val_indx]\n",
    "    \n",
    "        pred = train['310_PV_1'][-1]\n",
    "    \n",
    "    \n",
    "        error = 0.5*(test['310_PV_1'][0] - pred)**2\n",
    "        mse3.append(error)\n",
    "        \n",
    "    print(mse3)\n",
    "    return mse3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77388f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModels(df):\n",
    "    tss = TimeSeriesSplit(n_splits = 5, test_size = 20, gap = 0)\n",
    "    scaler = MinMaxScaler()\n",
    "    mse1 = model1(tss,scaler,df)\n",
    "    mse2 = modelNaive(tss,df)\n",
    "    \n",
    "    return mse1, mse2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84818b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = df[df.index.month.isin([1,2,3])]\n",
    "df2 = df[df.index.month.isin([4,5,6])]\n",
    "df3 = df[df.index.month.isin([7,8,9])]\n",
    "df4 = df[df.index.month.isin([10,11,12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30e29b2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "8633/8633 [==============================] - 18s 2ms/step - loss: 0.0069\n",
      "Epoch 2/50\n",
      "8633/8633 [==============================] - 17s 2ms/step - loss: 0.0046\n",
      "Epoch 3/50\n",
      "8633/8633 [==============================] - 17s 2ms/step - loss: 0.0044\n",
      "Epoch 4/50\n",
      "8633/8633 [==============================] - 16s 2ms/step - loss: 0.0044\n",
      "Epoch 5/50\n",
      "8633/8633 [==============================] - 18s 2ms/step - loss: 0.0043\n",
      "Epoch 6/50\n",
      "8633/8633 [==============================] - 17s 2ms/step - loss: 0.0042\n",
      "Epoch 7/50\n",
      "8633/8633 [==============================] - 14s 2ms/step - loss: 0.0042\n",
      "Epoch 8/50\n",
      "8633/8633 [==============================] - 18s 2ms/step - loss: 0.0042\n",
      "Epoch 9/50\n",
      "8633/8633 [==============================] - 16s 2ms/step - loss: 0.0041\n",
      "Epoch 10/50\n",
      "8633/8633 [==============================] - 17s 2ms/step - loss: 0.0041\n",
      "Epoch 11/50\n",
      "8633/8633 [==============================] - 18s 2ms/step - loss: 0.0041\n",
      "Epoch 12/50\n",
      "8633/8633 [==============================] - 30s 3ms/step - loss: 0.0041\n",
      "Epoch 13/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0041\n",
      "Epoch 14/50\n",
      "8633/8633 [==============================] - 25s 3ms/step - loss: 0.0041\n",
      "Epoch 15/50\n",
      "8633/8633 [==============================] - 28s 3ms/step - loss: 0.0041\n",
      "Epoch 16/50\n",
      "8633/8633 [==============================] - 25s 3ms/step - loss: 0.0040\n",
      "Epoch 17/50\n",
      "8633/8633 [==============================] - 25s 3ms/step - loss: 0.0040\n",
      "Epoch 18/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0040\n",
      "Epoch 19/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0040\n",
      "Epoch 20/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0040\n",
      "Epoch 21/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0040\n",
      "Epoch 22/50\n",
      "8633/8633 [==============================] - 30s 3ms/step - loss: 0.0040\n",
      "Epoch 23/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0040\n",
      "Epoch 24/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0039\n",
      "Epoch 25/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0040\n",
      "Epoch 26/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0040\n",
      "Epoch 27/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0040\n",
      "Epoch 28/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 29/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 30/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0039\n",
      "Epoch 31/50\n",
      "8633/8633 [==============================] - 28s 3ms/step - loss: 0.0039\n",
      "Epoch 32/50\n",
      "8633/8633 [==============================] - 25s 3ms/step - loss: 0.0039\n",
      "Epoch 33/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 34/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0039\n",
      "Epoch 35/50\n",
      "8633/8633 [==============================] - 28s 3ms/step - loss: 0.0039\n",
      "Epoch 36/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0039\n",
      "Epoch 37/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 38/50\n",
      "8633/8633 [==============================] - 36s 4ms/step - loss: 0.0039\n",
      "Epoch 39/50\n",
      "8633/8633 [==============================] - 30s 4ms/step - loss: 0.0039\n",
      "Epoch 40/50\n",
      "8633/8633 [==============================] - 27s 3ms/step - loss: 0.0039\n",
      "Epoch 41/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0038\n",
      "Epoch 42/50\n",
      "8633/8633 [==============================] - 25s 3ms/step - loss: 0.0039\n",
      "Epoch 43/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 44/50\n",
      "8633/8633 [==============================] - 30s 3ms/step - loss: 0.0038\n",
      "Epoch 45/50\n",
      "8633/8633 [==============================] - 32s 4ms/step - loss: 0.0038\n",
      "Epoch 46/50\n",
      "8633/8633 [==============================] - 24s 3ms/step - loss: 0.0039\n",
      "Epoch 47/50\n",
      "8633/8633 [==============================] - 25s 3ms/step - loss: 0.0039\n",
      "Epoch 48/50\n",
      "8633/8633 [==============================] - 23s 3ms/step - loss: 0.0038\n",
      "Epoch 49/50\n",
      "8633/8633 [==============================] - 26s 3ms/step - loss: 0.0038\n",
      "Epoch 50/50\n",
      "8633/8633 [==============================] - 24s 3ms/step - loss: 0.0039\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000258FFA16A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0068\n",
      "Epoch 2/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0047\n",
      "Epoch 3/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0046\n",
      "Epoch 4/50\n",
      "8653/8653 [==============================] - 29s 3ms/step - loss: 0.0045\n",
      "Epoch 5/50\n",
      "8653/8653 [==============================] - 24s 3ms/step - loss: 0.0044\n",
      "Epoch 6/50\n",
      "8653/8653 [==============================] - 24s 3ms/step - loss: 0.0043\n",
      "Epoch 7/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0043\n",
      "Epoch 8/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0042\n",
      "Epoch 9/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0041\n",
      "Epoch 10/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0041\n",
      "Epoch 11/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0041\n",
      "Epoch 12/50\n",
      "8653/8653 [==============================] - 29s 3ms/step - loss: 0.0041\n",
      "Epoch 13/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0041\n",
      "Epoch 14/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0040\n",
      "Epoch 15/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0040\n",
      "Epoch 16/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0040\n",
      "Epoch 17/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0040\n",
      "Epoch 18/50\n",
      "8653/8653 [==============================] - 24s 3ms/step - loss: 0.0040\n",
      "Epoch 19/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0040\n",
      "Epoch 20/50\n",
      "8653/8653 [==============================] - 29s 3ms/step - loss: 0.0040\n",
      "Epoch 21/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0040\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8653/8653 [==============================] - 33s 4ms/step - loss: 0.0039\n",
      "Epoch 23/50\n",
      "8653/8653 [==============================] - 28s 3ms/step - loss: 0.0040\n",
      "Epoch 24/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 25/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0039\n",
      "Epoch 26/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 27/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 28/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0039\n",
      "Epoch 29/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0039\n",
      "Epoch 30/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0039\n",
      "Epoch 31/50\n",
      "8653/8653 [==============================] - 31s 4ms/step - loss: 0.0039\n",
      "Epoch 32/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0039\n",
      "Epoch 33/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0039\n",
      "Epoch 34/50\n",
      "8653/8653 [==============================] - 29s 3ms/step - loss: 0.0039\n",
      "Epoch 35/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0038\n",
      "Epoch 36/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0038\n",
      "Epoch 37/50\n",
      "8653/8653 [==============================] - 31s 4ms/step - loss: 0.0038\n",
      "Epoch 38/50\n",
      "8653/8653 [==============================] - 31s 4ms/step - loss: 0.0039\n",
      "Epoch 39/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0038\n",
      "Epoch 40/50\n",
      "8653/8653 [==============================] - 31s 4ms/step - loss: 0.0038\n",
      "Epoch 41/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0038\n",
      "Epoch 42/50\n",
      "8653/8653 [==============================] - 32s 4ms/step - loss: 0.0038\n",
      "Epoch 43/50\n",
      "8653/8653 [==============================] - 30s 3ms/step - loss: 0.0038\n",
      "Epoch 44/50\n",
      "8653/8653 [==============================] - 30s 3ms/step - loss: 0.0038\n",
      "Epoch 45/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0038\n",
      "Epoch 46/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0038\n",
      "Epoch 47/50\n",
      "8653/8653 [==============================] - 27s 3ms/step - loss: 0.0038\n",
      "Epoch 48/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0038\n",
      "Epoch 49/50\n",
      "8653/8653 [==============================] - 26s 3ms/step - loss: 0.0038\n",
      "Epoch 50/50\n",
      "8653/8653 [==============================] - 25s 3ms/step - loss: 0.0038\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "8673/8673 [==============================] - 31s 3ms/step - loss: 0.0067\n",
      "Epoch 2/50\n",
      "8673/8673 [==============================] - 24s 3ms/step - loss: 0.0047\n",
      "Epoch 3/50\n",
      "8673/8673 [==============================] - 25s 3ms/step - loss: 0.0046\n",
      "Epoch 4/50\n",
      "8673/8673 [==============================] - 26s 3ms/step - loss: 0.0045\n",
      "Epoch 5/50\n",
      "8673/8673 [==============================] - 26s 3ms/step - loss: 0.0044\n",
      "Epoch 6/50\n",
      "8673/8673 [==============================] - 25s 3ms/step - loss: 0.0043\n",
      "Epoch 7/50\n",
      "8673/8673 [==============================] - 26s 3ms/step - loss: 0.0042\n",
      "Epoch 8/50\n",
      "8673/8673 [==============================] - 26s 3ms/step - loss: 0.0042\n",
      "Epoch 9/50\n",
      "8673/8673 [==============================] - 25s 3ms/step - loss: 0.0041\n",
      "Epoch 10/50\n",
      "8673/8673 [==============================] - 25s 3ms/step - loss: 0.0041\n",
      "Epoch 11/50\n",
      "8673/8673 [==============================] - 26s 3ms/step - loss: 0.0041\n",
      "Epoch 12/50\n",
      "8673/8673 [==============================] - 33s 4ms/step - loss: 0.0041\n",
      "Epoch 13/50\n",
      "7468/8673 [========================>.....] - ETA: 4s - loss: 0.0041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse1, mse2 = runModels(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse3, mse4 = runModels(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse5, mse6 = runModels(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse7, mse8 = runModels(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('season 1')\n",
    "\n",
    "print('model 1:')\n",
    "print(mse1)\n",
    "print('model Naive:')\n",
    "print(mse2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbff86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('season 1')\n",
    "\n",
    "print('model 1:')\n",
    "print(mse3)\n",
    "print('model Naive:')\n",
    "print(mse4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d77497",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('season 1')\n",
    "\n",
    "print('model 1:')\n",
    "print(mse5)\n",
    "print('model Naive:')\n",
    "print(mse6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d88820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('season 1')\n",
    "\n",
    "print('model 1:')\n",
    "print(mse7)\n",
    "print('model Naive:')\n",
    "print(mse8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879ae20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
